# ğŸ¤– RAG Chatbot - Intelligent Document Q&A System

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://python.org)
[![Django](https://img.shields.io/badge/Django-5.2.6-green.svg)](https://djangoproject.com)
[![React](https://img.shields.io/badge/React-19.1.1-blue.svg)](https://reactjs.org)
[![LangChain](https://img.shields.io/badge/LangChain-0.3.27-orange.svg)](https://langchain.com)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-1.0.20-purple.svg)](https://chromadb.com)

A sophisticated **Retrieval-Augmented Generation (RAG)** chatbot that allows users to upload documents and ask intelligent questions about their content. Built with Django REST API backend and React frontend, powered by LangChain and ChromaDB for vector storage.

## ğŸ“‹ Table of Contents

- [What is RAG?](#what-is-rag)
- [Features](#features)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Screenshots](#screenshots)
- [Installation & Setup](#installation--setup)
- [API Documentation](#api-documentation)
- [Usage Guide](#usage-guide)
- [Configuration](#configuration)
- [Project Structure](#project-structure)

## ğŸ” What is RAG?

**Retrieval-Augmented Generation (RAG)** is an advanced AI technique that combines the power of information retrieval with text generation. Here's how it works:

### The RAG Process:

1. **ğŸ“š Document Ingestion**: Documents are uploaded and processed into smaller, searchable chunks
2. **ğŸ”¢ Vectorization**: Text chunks are converted into high-dimensional vectors using embedding models
3. **ğŸ—„ï¸ Storage**: Vectors are stored in a vector database (ChromaDB) for fast similarity search
4. **ğŸ” Retrieval**: When a user asks a question, the system finds the most relevant document chunks
5. **ğŸ¤– Generation**: A language model generates an answer using the retrieved context
6. **ğŸ“ Response**: The user receives an accurate, source-backed answer

### Why RAG Matters:

- **ğŸ¯ Accuracy**: Answers are grounded in actual documents, reducing hallucinations
- **ğŸ“– Source Attribution**: Users can see which documents informed the answer
- **ğŸ”„ Real-time Knowledge**: No need to retrain models when documents change
- **ğŸ’¡ Context-Aware**: Understands the specific content of your documents
- **ğŸš€ Scalable**: Can handle large document collections efficiently

### Use Cases:

- **ğŸ“Š Corporate Knowledge Base**: Answer questions about company policies, procedures, and documentation
- **ğŸ“ Educational Content**: Help students find information in textbooks and research papers
- **âš–ï¸ Legal Document Analysis**: Quickly find relevant information in contracts and legal documents
- **ğŸ”¬ Research Assistance**: Analyze scientific papers and research findings
- **ğŸ“ˆ Business Intelligence**: Query reports, analytics, and business documents
- **ğŸ› ï¸ Technical Documentation**: Help developers find information in code documentation

## âœ¨ Features

### ğŸ” User Authentication
- Secure user registration and login
- JWT-based authentication
- User-specific document isolation

### ğŸ“„ Document Management
- **Multi-format Support**: PDF, TXT, MD, CSV, LOG files
- **Drag & Drop Upload**: Intuitive file upload interface
- **Batch Processing**: Upload multiple documents simultaneously
- **Document Metadata**: Track file size, upload date, and source labels
- **Document Deletion**: Remove documents from your knowledge base

### ğŸ§  Intelligent Q&A
- **Context-Aware Responses**: Answers based on your specific documents
- **Source Citations**: See which documents informed each answer
- **Similarity Scoring**: Understand how relevant each source is
- **Configurable Retrieval**: Adjust the number of relevant chunks retrieved

### ğŸ¨ Modern UI/UX
- **Responsive Design**: Works on desktop, tablet, and mobile
- **Real-time Chat Interface**: Smooth conversation experience
- **Document Sidebar**: Easy access to your uploaded documents
- **Loading States**: Clear feedback during processing
- **Error Handling**: User-friendly error messages

### âš™ï¸ Advanced Configuration
- **Multiple LLM Providers**: Support for Google Gemini, OpenAI, and Hugging Face models
- **Embedding Models**: Configurable text embedding models
- **Vector Database**: Persistent storage with ChromaDB
- **CORS Support**: Ready for production deployment

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚    â”‚  Django Backend  â”‚    â”‚   Vector Store  â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚   (ChromaDB)    â”‚
â”‚  â€¢ Chat UI      â”‚â—„â”€â”€â–ºâ”‚  â€¢ REST API      â”‚â—„â”€â”€â–ºâ”‚  â€¢ Embeddings   â”‚
â”‚  â€¢ Upload UI    â”‚    â”‚  â€¢ Authenticationâ”‚    â”‚  â€¢ Similarity   â”‚
â”‚  â€¢ Auth Context â”‚    â”‚  â€¢ Document Mgmt â”‚    â”‚    Search       â”‚
â”‚  â€¢ Routing      â”‚    â”‚  â€¢ RAG Pipeline  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Browser  â”‚    â”‚   SQLite DB     â”‚    â”‚  File Storage   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  â€¢ Session Mgmt â”‚    â”‚  â€¢ User Data    â”‚    â”‚  â€¢ Uploaded     â”‚
â”‚  â€¢ JWT Tokens   â”‚    â”‚  â€¢ Document     â”‚    â”‚    Documents    â”‚
â”‚                 â”‚    â”‚    Metadata     â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow:

1. **Document Upload**: User uploads files â†’ Django processes â†’ ChromaDB stores vectors
2. **Query Processing**: User asks question â†’ Vector similarity search â†’ Context retrieval â†’ LLM generation â†’ Response
3. **Authentication**: JWT tokens manage user sessions and document access

## ğŸ› ï¸ Tech Stack

### Backend
- **Django 5.2.6**: Web framework and API
- **Django REST Framework**: API development
- **LangChain 0.3.27**: RAG pipeline orchestration
- **ChromaDB 1.0.20**: Vector database for embeddings
- **Sentence Transformers**: Text embedding models
- **Google Gemini API**: Language model for generation
- **SQLite**: User and document metadata storage

### Frontend
- **React 19.1.1**: User interface framework
- **Vite**: Build tool and development server
- **Tailwind CSS**: Utility-first CSS framework
- **Axios**: HTTP client for API communication
- **React Router**: Client-side routing

### AI/ML Components
- **Embedding Model**: `sentence-transformers/all-MiniLM-L6-v2`
- **Language Model**: Google Gemini 2.5 Flash
- **Text Splitting**: Recursive character text splitter
- **Document Loaders**: PDF, text, and other format support

## ğŸ–¼ï¸ Screenshots

**Login Page:**

![Login Page](./Images_demo/login.png)

**Document Upload:**

![Document Upload](./Images_demo/DocUpload.png)

**Chat Interface With Document Management:**

![Chat Interface](./Images_demo/ChatInterface.png)

## ğŸš€ Installation & Setup

### Prerequisites

- **Python 3.12+**
- **Node.js 18+**
- **npm** or **yarn**
- **Git**

### 1. Clone the Repository

```bash
git clone https://github.com/utsav1072/RAG/
cd RAG
```

### 2. Backend Setup

#### Create Virtual Environment
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

#### Install Dependencies
```bash
pip install -r requirements.txt
```

#### Environment Configuration
Create a `.env` file in the `rag_chatbot` directory:

```env
# Django Configuration
DJANGO_SECRETE_KEY=your-secret-key-here
DEBUG=True

# Gemini API Configuration
GEMINI_API_KEY=your-gemini-api-key-here

# Optional: Customize RAG Settings
RAG_EMBEDDINGS_PROVIDER=huggingface
RAG_HF_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
RAG_LLM_PROVIDER=huggingface
RAG_LLM_MODEL=gemini-2.5-flash
RAG_LLM_MAX_TOKENS=512
RAG_FETCH_K=20
RAG_SCORE_THRESHOLD=0.2
```

#### Database Setup
```bash
cd rag_chatbot
python manage.py makemigrations
python manage.py migrate
python manage.py createsuperuser
```

#### Start Backend Server
```bash
python manage.py runserver
```

The backend will be available at `http://localhost:8000`

### 3. Frontend Setup

#### Navigate to Frontend Directory
```bash
cd frontend/chat_ui
```

#### Install Dependencies
```bash
npm install
```

#### Start Development Server
```bash
npm run dev
```

The frontend will be available at `http://localhost:5173`

### 4. Access the Application

1. Open your browser and go to `http://localhost:5173`
2. Register a new account or login
3. Upload documents to build your knowledge base
4. Start asking questions!

## ğŸ“š API Documentation

### Authentication Endpoints

#### Register User
```http
POST /api/auth/register/
Content-Type: application/json

{
    "username": "your_username",
    "email": "your_email@example.com",
    "password": "your_password"
}
```

#### Login
```http
POST /api/auth/token/
Content-Type: application/json

{
    "username": "your_username",
    "password": "your_password"
}
```

#### Get User Info
```http
GET /api/auth/me/
Authorization: Bearer <your_jwt_token>
```

### Document Management

#### Upload Documents
```http
POST /api/documents/upload/
Authorization: Bearer <your_jwt_token>
Content-Type: multipart/form-data

files: [file1, file2, ...]
source: "optional_source_label"
```

#### Get User Documents
```http
GET /api/documents/
Authorization: Bearer <your_jwt_token>
```

#### Delete Document
```http
DELETE /api/documents/{document_id}/delete/
Authorization: Bearer <your_jwt_token>
```

### RAG Query

#### Ask Question
```http
POST /api/query/
Authorization: Bearer <your_jwt_token>
Content-Type: application/json

{
    "query": "What is the main topic of the document?",
    "top_k": 4,
    "generate": true,
    "temperature": 0.7
}
```

#### Response Format
```json
{
    "results": [
        {
            "content": "Document chunk content...",
            "metadata": {
                "source": "document.pdf",
                "page": 1
            },
            "score": 0.85
        }
    ],
    "answer": "Generated answer based on retrieved context...",
    "citations": ["[1]", "[2]"]
}
```

## ğŸ“– Usage Guide

### Getting Started

1. **Create Account**: Register with a username, email, and password
2. **Upload Documents**: Use the upload page to add PDFs, text files, or other supported formats
3. **Start Chatting**: Navigate to the chat page and ask questions about your documents

### Best Practices

#### Document Upload
- **File Size**: Keep individual files under 20MB for optimal performance
- **File Types**: PDFs work best, but TXT, MD, CSV, and LOG files are also supported
- **Source Labels**: Add descriptive labels to organize your documents
- **Batch Upload**: Upload related documents together for better context

#### Asking Questions
- **Be Specific**: Ask detailed questions for better answers
- **Use Keywords**: Include relevant terms from your documents
- **Follow-up Questions**: Build on previous answers for deeper insights
- **Check Citations**: Review source documents for additional context

#### Document Management
- **Regular Cleanup**: Remove outdated or irrelevant documents
- **Organize by Topic**: Use source labels to group related documents
- **Monitor Usage**: Check which documents are most frequently referenced

### Example Queries

```
"What are the main findings in the research paper?"
"Summarize the key points from the company handbook"
"What procedures should I follow for customer complaints?"
"Find information about the new product launch strategy"
"What are the safety guidelines mentioned in the manual?"
```

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DJANGO_SECRETE_KEY` | Django secret key | Required |
| `GEMINI_API_KEY` | Google Gemini API key | Required |
| `RAG_EMBEDDINGS_PROVIDER` | Embedding provider | `huggingface` |
| `RAG_HF_MODEL_NAME` | Hugging Face model | `sentence-transformers/all-MiniLM-L6-v2` |
| `RAG_LLM_PROVIDER` | LLM provider | `huggingface` |
| `RAG_LLM_MODEL` | Language model | `gemini-2.5-flash` |
| `RAG_LLM_MAX_TOKENS` | Max tokens for generation | `512` |
| `RAG_FETCH_K` | Documents to retrieve | `20` |
| `RAG_SCORE_THRESHOLD` | Similarity threshold | `0.2` |

### Customization Options

#### Embedding Models
You can use different embedding models by changing the `RAG_HF_MODEL_NAME`:

```env
# For better performance (larger model)
RAG_HF_MODEL_NAME=sentence-transformers/all-mpnet-base-v2

# For faster processing (smaller model)
RAG_HF_MODEL_NAME=sentence-transformers/all-MiniLM-L12-v2
```

#### Language Models
Switch between different LLM providers:

```env
# Google Gemini (recommended)
RAG_LLM_PROVIDER=huggingface
RAG_LLM_MODEL=gemini-2.5-flash

# OpenAI (requires OpenAI API key)
RAG_LLM_PROVIDER=openai
RAG_OPENAI_MODEL=gpt-4o-mini
```

## ğŸ“ Project Structure

```
RAG/
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ chat_ui/                 # React frontend application
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ auth/           # Authentication components
â”‚       â”‚   â”œâ”€â”€ components/     # Reusable UI components
â”‚       â”‚   â”œâ”€â”€ pages/          # Main application pages
â”‚       â”‚   â””â”€â”€ assets/         # Static assets
â”‚       â”œâ”€â”€ package.json        # Frontend dependencies
â”‚       â””â”€â”€ vite.config.js      # Vite configuration
â”œâ”€â”€ rag_chatbot/                # Django backend application
â”‚   â”œâ”€â”€ chatbot/                # Main Django app
â”‚   â”‚   â”œâ”€â”€ models.py          # Database models
â”‚   â”‚   â”œâ”€â”€ views.py           # API views
â”‚   â”‚   â”œâ”€â”€ serializers.py     # Data serializers
â”‚   â”‚   â””â”€â”€ urls.py            # URL routing
â”‚   â”œâ”€â”€ rag_chatbot/           # Django project settings
â”‚   â”‚   â”œâ”€â”€ settings.py        # Configuration
â”‚   â”‚   â””â”€â”€ urls.py            # Main URL configuration
â”‚   â”œâ”€â”€ chroma/                # ChromaDB vector storage
â”‚   â”œâ”€â”€ media/                 # Uploaded files
â”‚   â””â”€â”€ manage.py              # Django management script
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                  # This file
```

### Key Files Explained

- **`models.py`**: Defines the Document model for tracking uploaded files
- **`views.py`**: Contains API endpoints for authentication, document upload, and RAG queries
- **`serializers.py`**: Handles data validation and serialization
- **`settings.py`**: Django configuration including RAG and database settings
- **`ChatPage.jsx`**: Main chat interface component
- **`UploadPage.jsx`**: Document upload interface
- **`AuthContext.jsx`**: Authentication state management


## ğŸ™ Acknowledgments

- **LangChain**: For the excellent RAG framework
- **ChromaDB**: For vector storage capabilities
- **Google**: For the Gemini language model
- **Django**: For the robust web framework
- **React**: For the modern frontend framework
- **Tailwind CSS**: For the beautiful styling system

*This project demonstrates modern RAG implementation with a focus on user experience, scalability, and maintainability.*
